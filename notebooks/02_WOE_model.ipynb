{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bibliotecas y configuración",
   "id": "6f057f5e415357a4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T21:45:42.696064Z",
     "start_time": "2025-11-10T21:45:42.259508Z"
    }
   },
   "source": [
    "# Imports (solo aquí)\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "\n",
    "# Parámetros generales\n",
    "TEST_SIZE     = 0.20\n",
    "RANDOM_STATE  = 42\n",
    "MIN_IV_SELECT = 0.02\n",
    "MAX_VARS      = 120\n",
    "\n",
    "# --------- localizar raíz del proyecto de forma robusta ----------\n",
    "def find_repo_root(start: Path, max_hops: int = 6) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(max_hops):\n",
    "        if (p / \".git\").exists() or (p / \"pyproject.toml\").exists() or (p / \"data\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return start.resolve()  # fallback (mejor que repetir data/interim)\n",
    "\n",
    "\n",
    "CWD = Path.cwd()\n",
    "BASE_DIR = Path.cwd().resolve().parent  # raíz del repo\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "INTERIM_DIR = DATA_DIR / \"interim\"\n",
    "REFERENCES_DIR = BASE_DIR / \"references\"\n",
    "REPORTS_DIR = BASE_DIR / \"reports\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "REPORTS_IV_DIR = REPORTS_DIR / \"iv\"\n",
    "\n",
    "# --------- carga ABT y selección por IV ----------\n",
    "df = pd.read_csv(INTERIM_DIR / \"abt_PE2020_clean_min.csv\")\n",
    "\n",
    "TARGET = \"default_12m\"\n",
    "\n",
    "iv_all_df = pd.read_csv(REPORTS_IV_DIR / \"iv_ranking_all.csv\")[[\"variable\", \"iv\"]]\n",
    "vars_model = (\n",
    "    iv_all_df.query(\"iv >= @MIN_IV_SELECT\")\n",
    "             .sort_values(\"iv\", ascending=False)\n",
    "             .head(MAX_VARS)[\"variable\"]\n",
    "             .tolist()\n",
    ")\n",
    "\n",
    "# Guardar inventario de variables seleccionadas\n",
    "REFERENCES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "out_vars = REFERENCES_DIR / f\"vars_model_woe_{datetime.now():%Y%m%d}.csv\"\n",
    "pd.Series(vars_model, name=\"variable\").to_csv(out_vars, index=False)\n",
    "\n",
    "# --------- vista rápida para verificar rutas y tamaños ----------\n",
    "print(\"=== Rutas detectadas ===\")\n",
    "print(\"CWD      :\", CWD)\n",
    "print(\"BASE_DIR :\", BASE_DIR)\n",
    "print(\"INTERIM  :\", INTERIM_DIR)\n",
    "print(\"REFERENCES:\", REFERENCES_DIR)\n",
    "print(\"REPORTS  :\", REPORTS_DIR)\n",
    "print()\n",
    "\n",
    "print(f\"TARGET: {TARGET}\")\n",
    "print(f\"Variables seleccionadas: {len(vars_model)}\")\n",
    "print(\"Primeras 10:\", vars_model[:10])\n",
    "print(\"ABT shape:\", df.shape)\n",
    "print(\"Inventario guardado en:\", out_vars)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rutas detectadas ===\n",
      "CWD      : C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\\notebooks\n",
      "BASE_DIR : C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\n",
      "INTERIM  : C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\\data\\interim\n",
      "REFERENCES: C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\\references\n",
      "REPORTS  : C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\\reports\n",
      "\n",
      "TARGET: default_12m\n",
      "Variables seleccionadas: 120\n",
      "Primeras 10: ['mxdiasatramesinte', 'rat_ven_sact', 'saldo_vencido_12med', 'saldo_vencido_12max', 'rat_ven_sact_12med', 'saldo_vencido_6max', 'saldo_vencido_6med', 'salmxincicap_v', 'salmedincicap_v', 'limmedcont_v']\n",
      "ABT shape: (17524, 438)\n",
      "Inventario guardado en: C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\\references\\vars_model_woe_20251110.csv\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformación a WOE",
   "id": "60715f36941877d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:28:53.074701Z",
     "start_time": "2025-11-10T21:28:50.336883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Celda 2 — Transformación WOE + Split 80/20 (selección robusta de exportgroup y reconstrucción de WOE)\n",
    "# =========================\n",
    "\n",
    "def read_csv_robust(path: Path) -> pd.DataFrame:\n",
    "    seps = [None, \",\", \";\", \"\\t\", \"|\"]\n",
    "    encs = [\"utf-8-sig\", \"utf-8\", \"latin-1\"]\n",
    "    engines = [\"python\", \"c\"]\n",
    "    last_err = None\n",
    "    for sep in seps:\n",
    "        for enc in encs:\n",
    "            for eng in engines:\n",
    "                try:\n",
    "                    df = pd.read_csv(path, sep=sep, encoding=enc, engine=eng)\n",
    "                    if df.shape[1] == 1:\n",
    "                        continue\n",
    "                    return df\n",
    "                except Exception as e:\n",
    "                    last_err = e\n",
    "                    continue\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        raise last_err or RuntimeError(f\"No pude leer {path}\")\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "    return s.strip(\"_\")\n",
    "\n",
    "def pick_col(df: pd.DataFrame, candidates: list[str]) -> str:\n",
    "    norm_map = {_norm(c): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if _norm(c) in norm_map:\n",
    "            return norm_map[_norm(c)]\n",
    "    for nc, original in norm_map.items():\n",
    "        if any(_norm(c) in nc for c in candidates):\n",
    "            return original\n",
    "    raise KeyError(f\"No pude encontrar columnas tipo {candidates}. Columnas: {list(df.columns)}\")\n",
    "\n",
    "def normcols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "# --- localizar un exportgroup \"útil\" (detalle por bin) ---\n",
    "exp_candidates = sorted(REFERENCES_DIR.glob(\"exportgroup*.csv\"), reverse=True)\n",
    "exp_path = None\n",
    "exp_df = None\n",
    "\n",
    "for p in exp_candidates:\n",
    "    df_try = read_csv_robust(p)\n",
    "    df_try = normcols(df_try)\n",
    "\n",
    "    has_var  = any(_norm(c) in {_norm(\"variable\"), _norm(\"feature\"), _norm(\"var\")} for c in df_try.columns)\n",
    "    has_bin  = any(_norm(c) in {_norm(\"bin\"), _norm(\"grupo\"), _norm(\"categoria\"), _norm(\"category\")} for c in df_try.columns)\n",
    "    has_woe  = any(_norm(c) == _norm(\"woe\") for c in df_try.columns)\n",
    "    has_dist = any(_norm(c) == _norm(\"dist_bad\") for c in df_try.columns) and any(_norm(c) == _norm(\"dist_good\") for c in df_try.columns)\n",
    "    has_bg   = any(_norm(c) == _norm(\"bads\") for c in df_try.columns) and any(_norm(c) == _norm(\"goods\") for c in df_try.columns)\n",
    "\n",
    "    # requisito mínimo: variable + bin + (woe o dist_* o bads/goods)\n",
    "    if has_var and has_bin and (has_woe or has_dist or has_bg):\n",
    "        exp_path = p\n",
    "        exp_df   = df_try\n",
    "        break\n",
    "\n",
    "if exp_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encontré un exportgroup con detalle por bin en references/ \"\n",
    "        \"(debe tener columnas variable+bin y woe o dist_* o bads/goods).\"\n",
    "    )\n",
    "\n",
    "# --- localizar catálogo numérico ---\n",
    "num_candidates = sorted(REFERENCES_DIR.glob(\"numeric_bins_catalog_*.csv\"), reverse=True)\n",
    "if not num_candidates:\n",
    "    raise FileNotFoundError(\"No encontré numeric_bins_catalog_*.csv en references/\")\n",
    "num_path = num_candidates[0]\n",
    "num = normcols(read_csv_robust(num_path))\n",
    "\n",
    "# --- mapear columnas del exportgroup ---\n",
    "col_var_exp = pick_col(exp_df, [\"variable\", \"feature\", \"var\"])\n",
    "col_bin_exp = pick_col(exp_df, [\"bin\", \"grupo\", \"categoria\", \"category\"])\n",
    "\n",
    "# Determinar cómo obtener WOE\n",
    "woe_col_present = any(_norm(c) == _norm(\"woe\") for c in exp_df.columns)\n",
    "if woe_col_present:\n",
    "    col_woe_exp = pick_col(exp_df, [\"woe\"])\n",
    "else:\n",
    "    # intentar reconstruir\n",
    "    dist_bad_present  = any(_norm(c) == _norm(\"dist_bad\") for c in exp_df.columns)\n",
    "    dist_good_present = any(_norm(c) == _norm(\"dist_good\") for c in exp_df.columns)\n",
    "    if dist_bad_present and dist_good_present:\n",
    "        col_db = pick_col(exp_df, [\"dist_bad\"])\n",
    "        col_dg = pick_col(exp_df, [\"dist_good\"])\n",
    "        exp_df[\"__woe__\"] = np.log(\n",
    "            exp_df[col_db].replace(0, np.nan) / exp_df[col_dg].replace(0, np.nan)\n",
    "        ).fillna(0.0)\n",
    "        col_woe_exp = \"__woe__\"\n",
    "    else:\n",
    "        # último intento: usar bads/goods y totales reales de la ABT\n",
    "        if not (any(_norm(c) == _norm(\"bads\") for c in exp_df.columns) and\n",
    "                any(_norm(c) == _norm(\"goods\") for c in exp_df.columns)):\n",
    "            raise KeyError(\n",
    "                \"El exportgroup seleccionado no tiene ni woe, ni dist_bad/dist_good, \"\n",
    "                \"ni bads/goods. No puedo construir WOE.\"\n",
    "            )\n",
    "        col_bads  = pick_col(exp_df, [\"bads\"])\n",
    "        col_goods = pick_col(exp_df, [\"goods\"])\n",
    "        total_bads  = int(df[TARGET].sum())\n",
    "        total_goods = int(len(df) - total_bads)\n",
    "        exp_df[\"__dist_bad__\"]  = exp_df[col_bads]  / max(total_bads, 1)\n",
    "        exp_df[\"__dist_good__\"] = exp_df[col_goods] / max(total_goods, 1)\n",
    "        exp_df[\"__woe__\"] = np.log(\n",
    "            exp_df[\"__dist_bad__\"].replace(0, np.nan) / exp_df[\"__dist_good__\"].replace(0, np.nan)\n",
    "        ).fillna(0.0)\n",
    "        col_woe_exp = \"__woe__\"\n",
    "\n",
    "# --- Diccionario (variable, bin) -> WOE\n",
    "woe_map = (\n",
    "    exp_df[[col_var_exp, col_bin_exp, col_woe_exp]]\n",
    "    .rename(columns={col_var_exp: \"variable\", col_bin_exp: \"bin\", col_woe_exp: \"woe\"})\n",
    "    .set_index([\"variable\", \"bin\"])[\"woe\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# --- columnas en numeric catalog (cortes numéricos) ---\n",
    "col_var_num = pick_col(num, [\"variable\", \"feature\", \"var\"])\n",
    "col_bin_num = pick_col(num, [\"bin\", \"grupo\", \"categoria\"])\n",
    "col_left    = pick_col(num, [\"left\", \"min\", \"low\", \"desde\", \"l\"])\n",
    "col_right   = pick_col(num, [\"right\", \"max\", \"high\", \"hasta\", \"r\"])\n",
    "\n",
    "num_std = (\n",
    "    num[[col_var_num, col_bin_num, col_left, col_right]]\n",
    "    .rename(columns={col_var_num: \"variable\", col_bin_num: \"bin\", col_left: \"left\", col_right: \"right\"})\n",
    ")\n",
    "num_std[\"left\"]  = pd.to_numeric(num_std[\"left\"], errors=\"coerce\")\n",
    "num_std[\"right\"] = pd.to_numeric(num_std[\"right\"], errors=\"coerce\")\n",
    "\n",
    "cuts_dict: dict[str, list[tuple[float, float, str]]] = {}\n",
    "for v, g in num_std.groupby(\"variable\"):\n",
    "    g = g.dropna(subset=[\"left\", \"right\"]).sort_values([\"left\", \"right\"])\n",
    "    cuts_dict[v] = list(zip(g[\"left\"].to_list(), g[\"right\"].to_list(), g[\"bin\"].to_list()))\n",
    "\n",
    "def assign_bin_numeric(val, cuts):\n",
    "    if pd.isna(val) or not cuts:\n",
    "        return None\n",
    "    for left, right, b in cuts:\n",
    "        if val > left and val <= right:   # (left, right]\n",
    "            return b\n",
    "    return None\n",
    "\n",
    "def to_woe_numeric(series: pd.Series, varname: str) -> pd.Series:\n",
    "    cuts = cuts_dict.get(varname, [])\n",
    "    if not cuts:\n",
    "        return pd.Series(0.0, index=series.index)\n",
    "    bins = series.apply(lambda x: assign_bin_numeric(x, cuts))\n",
    "    return bins.apply(lambda b: woe_map.get((varname, b), woe_map.get((varname, \"ALL\"), 0.0)))\n",
    "\n",
    "def to_woe_categorical(series: pd.Series, varname: str) -> pd.Series:\n",
    "    return series.astype(str).apply(\n",
    "        lambda cat: woe_map.get((varname, cat), woe_map.get((varname, \"ALL\"), 0.0))\n",
    "    )\n",
    "\n",
    "# --- construir matriz WOE con las vars seleccionadas que existan en df ---\n",
    "X_woe = pd.DataFrame(index=df.index)\n",
    "vars_in_df = [v for v in vars_model if v in df.columns]\n",
    "\n",
    "for v in vars_in_df:\n",
    "    if v in cuts_dict:\n",
    "        X_woe[v] = to_woe_numeric(df[v], v)\n",
    "    else:\n",
    "        X_woe[v] = to_woe_categorical(df[v], v)\n",
    "\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# --- split 80/20 estratificado ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_woe, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# --- guardar ---\n",
    "OUT_MODELS_INTERIM = INTERIM_DIR / \"models\"\n",
    "OUT_MODELS_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "X_train.to_csv(OUT_MODELS_INTERIM / \"X_train_woe.csv\", index=False)\n",
    "X_test.to_csv(OUT_MODELS_INTERIM / \"X_test_woe.csv\", index=False)\n",
    "y_train.to_csv(OUT_MODELS_INTERIM / \"y_train.csv\", index=False)\n",
    "y_test.to_csv(OUT_MODELS_INTERIM / \"y_test.csv\", index=False)\n",
    "\n",
    "print(\"Exportgroup usado:\", exp_path.name, \"| columnas:\", list(exp_df.columns)[:10], \"...\")\n",
    "print(\"Numeric catalog   :\", num_path.name,    \"| columnas:\", list(num.columns)[:10], \"...\")\n",
    "print(\"WOE matrix shape:\", X_woe.shape)\n",
    "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "print(\"Positive rate (train/test):\", y_train.mean().round(4), y_test.mean().round(4))\n"
   ],
   "id": "e77c59bb78565f5b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n",
      "C:\\Users\\PC RYU\\AppData\\Local\\Temp\\ipykernel_174160\\2868368442.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_woe[v] = to_woe_numeric(df[v], v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportgroup usado: exportgroup_20251103.csv | columnas: ['variable', 'var_type', 'bin', 'count', 'bads', 'goods', 'dist_bad', 'dist_good', 'woe', 'iv_component'] ...\n",
      "Numeric catalog   : numeric_bins_catalog_20251103.csv | columnas: ['variable', 'bin', 'segment', 'left', 'right', 'closed'] ...\n",
      "WOE matrix shape: (17524, 120)\n",
      "Train: (14019, 120) | Test: (3505, 120)\n",
      "Positive rate (train/test): 0.0527 0.0528\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Entrenamiento y evaluación",
   "id": "8761d97cbc62dd7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:28:56.286511Z",
     "start_time": "2025-11-10T21:28:55.392817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- rutas de E/S\n",
    "IN_MODELS_INTERIM = INTERIM_DIR / \"models\"\n",
    "OUT_MODELS_FINAL  = MODELS_DIR              # carpeta raíz /models\n",
    "OUT_REPORTS       = REPORTS_DIR             # carpeta raíz /reports\n",
    "OUT_FIGS          = REPORTS_DIR / \"figures\"\n",
    "OUT_REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FIGS.mkdir(parents=True, exist_ok=True)\n",
    "OUT_MODELS_FINAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- cargar matrices WOE\n",
    "X_train = pd.read_csv(IN_MODELS_INTERIM / \"X_train_woe.csv\")\n",
    "X_test  = pd.read_csv(IN_MODELS_INTERIM / \"X_test_woe.csv\")\n",
    "y_train = pd.read_csv(IN_MODELS_INTERIM / \"y_train.csv\").squeeze().astype(int)\n",
    "y_test  = pd.read_csv(IN_MODELS_INTERIM / \"y_test.csv\").squeeze().astype(int)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"| Test shape:\", X_test.shape)\n",
    "print(\"Pos rate (train/test):\", y_train.mean().round(4), y_test.mean().round(4))\n",
    "\n",
    "# --- modelo: Logistic Regression (WOE ya escalado; ponderación por desbalance)\n",
    "clf = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"liblinear\",\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=2000,\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "# entrenamiento\n",
    "t0 = datetime.now()\n",
    "clf.fit(X_train, y_train)\n",
    "t1 = datetime.now()\n",
    "print(f\"Tiempo de entrenamiento: {(t1 - t0).total_seconds():.2f}s\")\n",
    "\n",
    "# --- scoring\n",
    "train_score = clf.predict_proba(X_train)[:, 1]\n",
    "test_score  = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# --- métricas base\n",
    "roc_auc   = roc_auc_score(y_test, test_score)\n",
    "pr_auc    = average_precision_score(y_test, test_score)  # área bajo curva precisión-recall\n",
    "gini      = 2 * roc_auc - 1\n",
    "\n",
    "# KS\n",
    "fpr, tpr, thr = roc_curve(y_test, test_score)\n",
    "ks_values = tpr - fpr\n",
    "ks = float(np.max(ks_values))\n",
    "ks_thr = float(thr[np.argmax(ks_values)])\n",
    "\n",
    "print(f\"AUC ROC: {roc_auc:.4f} | PR AUC: {pr_auc:.4f} | Gini: {gini:.4f} | KS: {ks:.4f} @ thr≈{ks_thr:.4f}\")\n",
    "\n",
    "# --- umbral operativo (usamos el de máximo KS en validación)\n",
    "best_thr = ks_thr\n",
    "\n",
    "def confusion_at(th, y_true, score):\n",
    "    y_hat = (score >= th).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    return dict(threshold=float(th), TP=int(tp), FP=int(fp), TN=int(tn), FN=int(fn))\n",
    "\n",
    "cm_test = confusion_at(best_thr, y_test, test_score)\n",
    "print(\"Confusión (test) @KS:\", cm_test)\n",
    "\n",
    "# --- lift/top-decile y ganancias rápidas\n",
    "def top_decile_lift(y_true, score, pct=0.1):\n",
    "    n = len(score)\n",
    "    k = max(1, int(np.floor(n * pct)))\n",
    "    order = np.argsort(-score)\n",
    "    top_k = y_true.iloc[order[:k]].sum()\n",
    "    base  = y_true.mean() * k\n",
    "    return float((top_k / max(base, 1e-12)))\n",
    "\n",
    "lift10 = top_decile_lift(y_test, test_score, pct=0.10)\n",
    "print(f\"Lift Top 10%: {lift10:.2f}x\")\n",
    "\n",
    "# --- curvas y figuras\n",
    "# ROC\n",
    "plt.figure()\n",
    "fpr_tr, tpr_tr, _ = roc_curve(y_train, train_score)\n",
    "fpr_te, tpr_te, _ = roc_curve(y_test,  test_score)\n",
    "plt.plot(fpr_tr, tpr_tr, label=f\"Train ROC (AUC={roc_auc_score(y_train, train_score):.3f})\")\n",
    "plt.plot(fpr_te, tpr_te, label=f\"Test ROC (AUC={roc_auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],\"--\", lw=1, alpha=0.6)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve — Logistic (WOE)\")\n",
    "plt.legend()\n",
    "roc_path = OUT_FIGS / \"roc_woe_logreg.png\"\n",
    "plt.savefig(roc_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# PR\n",
    "plt.figure()\n",
    "prec, rec, _ = precision_recall_curve(y_test, test_score)\n",
    "plt.plot(rec, prec, label=f\"Test PR (AP={pr_auc:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall — Logistic (WOE)\")\n",
    "plt.legend()\n",
    "pr_path = OUT_FIGS / \"pr_woe_logreg.png\"\n",
    "plt.savefig(pr_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# KS curve\n",
    "plt.figure()\n",
    "plt.plot(thr, ks_values, label=\"KS(th)\")\n",
    "plt.axvline(best_thr, color=\"r\", ls=\"--\", label=f\"best thr={best_thr:.3f}\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"KS\")\n",
    "plt.title(\"KS vs Threshold — Logistic (WOE)\")\n",
    "plt.legend()\n",
    "ks_path = OUT_FIGS / \"ks_woe_logreg.png\"\n",
    "plt.savefig(ks_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# --- guardar modelo y reportes\n",
    "model_path = OUT_MODELS_FINAL / \"woe_logistic_regression.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(dict(model=clf, features=X_train.columns.tolist(), threshold=best_thr), f)\n",
    "\n",
    "metrics = dict(\n",
    "    timestamp=datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    n_features=X_train.shape[1],\n",
    "    auc_roc=float(roc_auc),\n",
    "    pr_auc=float(pr_auc),\n",
    "    gini=float(gini),\n",
    "    ks=float(ks),\n",
    "    ks_threshold=float(best_thr),\n",
    "    lift_top10=float(lift10),\n",
    "    pos_rate_train=float(y_train.mean()),\n",
    "    pos_rate_test=float(y_test.mean()),\n",
    "    confusion_test=cm_test,\n",
    "    paths=dict(roc=str(roc_path), pr=str(pr_path), ks=str(ks_path), model=str(model_path)),\n",
    ")\n",
    "with open(OUT_REPORTS / \"woe_logreg_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# --- archivo con scores de test (útil para auditoría)\n",
    "scores_path = OUT_REPORTS / \"scores_test_woe_logreg.csv\"\n",
    "pd.DataFrame({\"y_true\": y_test.values, \"score\": test_score}).to_csv(scores_path, index=False)\n",
    "\n",
    "print(\"Artefactos guardados:\")\n",
    "print(\"  Modelo   :\", model_path)\n",
    "print(\"  Métricas :\", OUT_REPORTS / 'woe_logreg_metrics.json')\n",
    "print(\"  Figuras  :\", roc_path.name, \",\", pr_path.name, \",\", ks_path.name)\n",
    "print(\"  Scores   :\", scores_path.name)\n"
   ],
   "id": "2f63f0bcc8a3b055",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (14019, 120) | Test shape: (3505, 120)\n",
      "Pos rate (train/test): 0.0527 0.0528\n",
      "Tiempo de entrenamiento: 0.40s\n",
      "AUC ROC: 0.8321 | PR AUC: 0.3749 | Gini: 0.6643 | KS: 0.5233 @ thr≈0.5515\n",
      "Confusión (test) @KS: {'threshold': 0.5514528368340634, 'TP': 123, 'FP': 470, 'TN': 2850, 'FN': 62}\n",
      "Lift Top 10%: 5.58x\n",
      "Artefactos guardados:\n",
      "  Modelo   : C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\\models\\woe_logistic_regression.pkl\n",
      "  Métricas : C:\\Users\\PC RYU\\Documents\\Galileo\\Maestria\\Product Development\\repo_proyecto_pe\\reports\\woe_logreg_metrics.json\n",
      "  Figuras  : roc_woe_logreg.png , pr_woe_logreg.png , ks_woe_logreg.png\n",
      "  Scores   : scores_test_woe_logreg.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Deciles, KS y ganancias",
   "id": "5c71625fbc26561f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:36:33.675719Z",
     "start_time": "2025-11-10T21:36:33.475466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- helper para deciles\n",
    "def to_deciles(scores, n=10):\n",
    "    # percentiles 0..100 en pasos de 10\n",
    "    q = np.linspace(0, 1, n+1)\n",
    "    cuts = np.quantile(scores, q)\n",
    "    # para que el decil 1 sea el de mayor riesgo, invertimos los cortes\n",
    "    cuts = np.unique(cuts)  # por si hay empates extremos\n",
    "    return cuts\n",
    "\n",
    "def decile_table(y_true, score, n=10):\n",
    "    # Ordenar de mayor a menor score (más riesgoso primero)\n",
    "    df_ = pd.DataFrame({\"y\": y_true.values, \"score\": score})\n",
    "    df_ = df_.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    df_[\"decile\"] = pd.qcut(df_.index, q=n, labels=[f\"D{i}\" for i in range(1, n+1)])\n",
    "\n",
    "    tab = (df_.groupby(\"decile\", observed=False)\n",
    "             .agg(\n",
    "                 count=(\"y\", \"size\"),\n",
    "                 bads=(\"y\", \"sum\"),\n",
    "                 avg_score=(\"score\", \"mean\")\n",
    "             )\n",
    "             .reset_index())\n",
    "    tab[\"goods\"] = tab[\"count\"] - tab[\"bads\"]\n",
    "    tab[\"bad_rate\"] = tab[\"bads\"] / tab[\"count\"]\n",
    "\n",
    "    # acumulados (decil 1 = más riesgoso)\n",
    "    tab[\"cum_bads\"] = tab[\"bads\"].cumsum()\n",
    "    tab[\"cum_goods\"] = tab[\"goods\"].cumsum()\n",
    "    total_bads = tab[\"bads\"].sum()\n",
    "    total_goods = tab[\"goods\"].sum()\n",
    "    tab[\"cum_capture_rate\"] = tab[\"cum_bads\"] / max(total_bads, 1)\n",
    "\n",
    "    # lift por decil y lift acumulado\n",
    "    overall_bad_rate = total_bads / (total_bads + total_goods)\n",
    "    tab[\"lift\"] = tab[\"bad_rate\"] / max(overall_bad_rate, 1e-12)\n",
    "    tab[\"cum_lift\"] = (tab[\"cum_bads\"] / tab[\"count\"].cumsum()) / max(overall_bad_rate, 1e-12)\n",
    "\n",
    "    # KS por decil (utilizando acumulados proporcionales)\n",
    "    tab[\"cum_bad_pct\"] = tab[\"cum_bads\"] / max(total_bads, 1)\n",
    "    tab[\"cum_good_pct\"] = tab[\"cum_goods\"] / max(total_goods, 1)\n",
    "    tab[\"ks_by_decile\"] = (tab[\"cum_bad_pct\"] - tab[\"cum_good_pct\"]).abs()\n",
    "\n",
    "    return tab\n",
    "\n",
    "deciles = decile_table(y_test, test_score, n=10)\n",
    "\n",
    "# --- guardar CSV\n",
    "out_csv = REPORTS_DIR / \"deciles_woe_logreg.csv\"\n",
    "deciles.to_csv(out_csv, index=False)\n",
    "\n",
    "# --- figuras simples (lift y KS por decil)\n",
    "fig1_path = REPORTS_DIR / \"figures\" / \"lift_by_decile_woe_logreg.png\"\n",
    "fig2_path = REPORTS_DIR / \"figures\" / \"ks_by_decile_woe_logreg.png\"\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(deciles[\"decile\"], deciles[\"lift\"], marker=\"o\")\n",
    "plt.title(\"Lift por decil (test)\")\n",
    "plt.xlabel(\"Decil (1=mayor riesgo)\")\n",
    "plt.ylabel(\"Lift\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig1_path, dpi=150)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(deciles[\"decile\"], deciles[\"ks_by_decile\"], marker=\"o\")\n",
    "plt.title(\"KS por decil (test)\")\n",
    "plt.xlabel(\"Decil (1=mayor riesgo)\")\n",
    "plt.ylabel(\"KS\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig2_path, dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Deciles guardados en:\", out_csv.name)\n",
    "print(\"Figuras:\", fig1_path.name, \",\", fig2_path.name)\n",
    "\n",
    "# vistazo rápido\n",
    "display(deciles)\n"
   ],
   "id": "d4c99e12ab74756b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deciles guardados en: deciles_woe_logreg.csv\n",
      "Figuras: lift_by_decile_woe_logreg.png , ks_by_decile_woe_logreg.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  decile  count  bads  avg_score  goods  bad_rate  cum_bads  cum_goods  \\\n",
       "0     D1    351   103   0.844888    248  0.293447       103        248   \n",
       "1     D2    350    24   0.590693    326  0.068571       127        574   \n",
       "2     D3    351    14   0.448408    337  0.039886       141        911   \n",
       "3     D4    350    12   0.372939    338  0.034286       153       1249   \n",
       "4     D5    351     9   0.325011    342  0.025641       162       1591   \n",
       "5     D6    350     3   0.280080    347  0.008571       165       1938   \n",
       "6     D7    350     9   0.225512    341  0.025714       174       2279   \n",
       "7     D8    351     9   0.161069    342  0.025641       183       2621   \n",
       "8     D9    350     1   0.094022    349  0.002857       184       2970   \n",
       "9    D10    351     1   0.035781    350  0.002849       185       3320   \n",
       "\n",
       "   cum_capture_rate      lift  cum_lift  cum_bad_pct  cum_good_pct  \\\n",
       "0          0.556757  5.559637  5.559637     0.556757      0.074699   \n",
       "1          0.686486  1.299151  3.432432     0.686486      0.172892   \n",
       "2          0.762162  0.755679  2.539333     0.762162      0.274398   \n",
       "3          0.827027  0.649575  2.067568     0.827027      0.376205   \n",
       "4          0.875676  0.485793  1.750852     0.875676      0.479217   \n",
       "5          0.891892  0.162394  1.486486     0.891892      0.583735   \n",
       "6          0.940541  0.487181  1.343903     0.940541      0.686446   \n",
       "7          0.989189  0.485793  1.236486     0.989189      0.789458   \n",
       "8          0.994595  0.054131  1.105280     0.994595      0.894578   \n",
       "9          1.000000  0.053977  1.000000     1.000000      1.000000   \n",
       "\n",
       "   ks_by_decile  \n",
       "0      0.482058  \n",
       "1      0.513595  \n",
       "2      0.487765  \n",
       "3      0.450822  \n",
       "4      0.396459  \n",
       "5      0.308157  \n",
       "6      0.254095  \n",
       "7      0.199731  \n",
       "8      0.100016  \n",
       "9      0.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decile</th>\n",
       "      <th>count</th>\n",
       "      <th>bads</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>goods</th>\n",
       "      <th>bad_rate</th>\n",
       "      <th>cum_bads</th>\n",
       "      <th>cum_goods</th>\n",
       "      <th>cum_capture_rate</th>\n",
       "      <th>lift</th>\n",
       "      <th>cum_lift</th>\n",
       "      <th>cum_bad_pct</th>\n",
       "      <th>cum_good_pct</th>\n",
       "      <th>ks_by_decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>351</td>\n",
       "      <td>103</td>\n",
       "      <td>0.844888</td>\n",
       "      <td>248</td>\n",
       "      <td>0.293447</td>\n",
       "      <td>103</td>\n",
       "      <td>248</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>5.559637</td>\n",
       "      <td>5.559637</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>0.074699</td>\n",
       "      <td>0.482058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>350</td>\n",
       "      <td>24</td>\n",
       "      <td>0.590693</td>\n",
       "      <td>326</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>127</td>\n",
       "      <td>574</td>\n",
       "      <td>0.686486</td>\n",
       "      <td>1.299151</td>\n",
       "      <td>3.432432</td>\n",
       "      <td>0.686486</td>\n",
       "      <td>0.172892</td>\n",
       "      <td>0.513595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>351</td>\n",
       "      <td>14</td>\n",
       "      <td>0.448408</td>\n",
       "      <td>337</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>141</td>\n",
       "      <td>911</td>\n",
       "      <td>0.762162</td>\n",
       "      <td>0.755679</td>\n",
       "      <td>2.539333</td>\n",
       "      <td>0.762162</td>\n",
       "      <td>0.274398</td>\n",
       "      <td>0.487765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>350</td>\n",
       "      <td>12</td>\n",
       "      <td>0.372939</td>\n",
       "      <td>338</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>153</td>\n",
       "      <td>1249</td>\n",
       "      <td>0.827027</td>\n",
       "      <td>0.649575</td>\n",
       "      <td>2.067568</td>\n",
       "      <td>0.827027</td>\n",
       "      <td>0.376205</td>\n",
       "      <td>0.450822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>351</td>\n",
       "      <td>9</td>\n",
       "      <td>0.325011</td>\n",
       "      <td>342</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>162</td>\n",
       "      <td>1591</td>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.485793</td>\n",
       "      <td>1.750852</td>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.479217</td>\n",
       "      <td>0.396459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D6</td>\n",
       "      <td>350</td>\n",
       "      <td>3</td>\n",
       "      <td>0.280080</td>\n",
       "      <td>347</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>165</td>\n",
       "      <td>1938</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.162394</td>\n",
       "      <td>1.486486</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.583735</td>\n",
       "      <td>0.308157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D7</td>\n",
       "      <td>350</td>\n",
       "      <td>9</td>\n",
       "      <td>0.225512</td>\n",
       "      <td>341</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>174</td>\n",
       "      <td>2279</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.487181</td>\n",
       "      <td>1.343903</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.686446</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D8</td>\n",
       "      <td>351</td>\n",
       "      <td>9</td>\n",
       "      <td>0.161069</td>\n",
       "      <td>342</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>183</td>\n",
       "      <td>2621</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.485793</td>\n",
       "      <td>1.236486</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.789458</td>\n",
       "      <td>0.199731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D9</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094022</td>\n",
       "      <td>349</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>184</td>\n",
       "      <td>2970</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>1.105280</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.894578</td>\n",
       "      <td>0.100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D10</td>\n",
       "      <td>351</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035781</td>\n",
       "      <td>350</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>185</td>\n",
       "      <td>3320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Selección de umbrales",
   "id": "295e7b3411d5092"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:45:57.478256Z",
     "start_time": "2025-11-10T21:45:48.678938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Cargar scores de test\n",
    "scores_path = REPORTS_DIR / \"scores_test_woe_logreg.csv\"\n",
    "df_sc = pd.read_csv(scores_path)\n",
    "y = df_sc[\"y_true\"].astype(int).values\n",
    "s = df_sc[\"score\"].values\n",
    "\n",
    "# 2) Curvas útiles\n",
    "prec, rec, thr_pr = precision_recall_curve(y, s)\n",
    "fpr, tpr, thr_roc  = roc_curve(y, s)\n",
    "\n",
    "# 3) KS (conjunto de umbrales de ROC)\n",
    "ks_vals = tpr - fpr\n",
    "idx_ks  = np.argmax(ks_vals)\n",
    "thr_ks  = thr_roc[idx_ks]\n",
    "ks_max  = ks_vals[idx_ks]\n",
    "\n",
    "# 4) F1 en una rejilla de umbrales\n",
    "grid = np.unique(np.r_[np.linspace(0.01, 0.99, 99), thr_roc, thr_pr])\n",
    "f1_list, p_list, r_list = [], [], []\n",
    "for t in grid:\n",
    "    yhat = (s >= t).astype(int)\n",
    "    # evitemos divisiones raras si no hay positivos predichos\n",
    "    if yhat.sum() == 0:\n",
    "        f1_list.append(0.0); p_list.append(0.0); r_list.append(0.0)\n",
    "        continue\n",
    "    f1_list.append(f1_score(y, yhat))\n",
    "    p_list.append(precision_score(y, yhat))\n",
    "    r_list.append(recall_score(y, yhat))\n",
    "\n",
    "idx_f1 = int(np.argmax(f1_list))\n",
    "thr_f1 = float(grid[idx_f1])\n",
    "\n",
    "# 5) Precision objetivo (ej: 30%) y Recall objetivo (ej: 60%) — ajusta a tu negocio\n",
    "target_precision = 0.30\n",
    "target_recall    = 0.60\n",
    "\n",
    "# umbral mínimo que alcanza al menos la precisión objetivo\n",
    "thr_p = None\n",
    "for t, p in sorted(zip(grid, p_list), key=lambda z: z[0]):\n",
    "    if p >= target_precision:\n",
    "        thr_p = float(t); break\n",
    "\n",
    "# umbral máximo que alcanza al menos el recall objetivo\n",
    "thr_r = None\n",
    "for t, r in sorted(zip(grid, r_list), key=lambda z: z[0]):\n",
    "    if r >= target_recall:\n",
    "        thr_r = float(t); break\n",
    "\n",
    "# 6) Top-N% (ej: 10% más riesgosos)\n",
    "top_rate = 0.10\n",
    "thr_top = float(np.quantile(s, 1 - top_rate))  # 10% superior = score alto\n",
    "\n",
    "def eval_at_threshold(t):\n",
    "    yhat = (s >= t).astype(int)\n",
    "    TP = int(((y==1)&(yhat==1)).sum())\n",
    "    FP = int(((y==0)&(yhat==1)).sum())\n",
    "    TN = int(((y==0)&(yhat==0)).sum())\n",
    "    FN = int(((y==1)&(yhat==0)).sum())\n",
    "    prec_ = precision_score(y, yhat) if (TP+FP)>0 else 0.0\n",
    "    rec_  = recall_score(y, yhat)    if (TP+FN)>0 else 0.0\n",
    "    f1_   = f1_score(y, yhat)        if (TP+FP)>0 else 0.0\n",
    "    rate_ = yhat.mean()\n",
    "    return dict(threshold=t, TP=TP, FP=FP, TN=TN, FN=FN,\n",
    "                precision=prec_, recall=rec_, f1=f1_, approve_rate=rate_)\n",
    "\n",
    "candidates = {\n",
    "    \"KS_max\"            : thr_ks,\n",
    "    \"F1_max\"            : thr_f1,\n",
    "    \"Prec>=30%\"         : thr_p,\n",
    "    \"Recall>=60%\"       : thr_r,\n",
    "    \"Top10%_score\"      : thr_top,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, t in candidates.items():\n",
    "    if t is None:\n",
    "        rows.append(dict(name=name, note=\"No alcanzado\", threshold=np.nan))\n",
    "        continue\n",
    "    m = eval_at_threshold(t)\n",
    "    m[\"name\"] = name\n",
    "    m[\"note\"] = \"\"\n",
    "    rows.append(m)\n",
    "\n",
    "thr_df = pd.DataFrame(rows)\n",
    "\n",
    "# 7) Guardar tabla de umbrales\n",
    "out_thr = REPORTS_DIR / \"thresholds_woe_logreg.csv\"\n",
    "thr_df.to_csv(out_thr, index=False)\n",
    "\n",
    "print(\"Tabla de umbrales guardada en:\", out_thr.name)\n",
    "display(thr_df.sort_values(\"threshold\"))\n"
   ],
   "id": "6f2d0d80a96ea3f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de umbrales guardada en: thresholds_woe_logreg.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   threshold   TP    FP    TN  FN  precision    recall        f1  \\\n",
       "3   0.005009  185  3320     0   0   0.052782  1.000000  0.100271   \n",
       "0   0.551453  123   470  2850  62   0.207420  0.664865  0.316195   \n",
       "4   0.690493  103   248  3072  82   0.293447  0.556757  0.384328   \n",
       "2   0.696021  103   240  3080  82   0.300292  0.556757  0.390152   \n",
       "1   0.790786   94   139  3181  91   0.403433  0.508108  0.449761   \n",
       "\n",
       "   approve_rate          name note  \n",
       "3      1.000000   Recall>=60%       \n",
       "0      0.169187        KS_max       \n",
       "4      0.100143  Top10%_score       \n",
       "2      0.097860     Prec>=30%       \n",
       "1      0.066476        F1_max       "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>approve_rate</th>\n",
       "      <th>name</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005009</td>\n",
       "      <td>185</td>\n",
       "      <td>3320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Recall&gt;=60%</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.551453</td>\n",
       "      <td>123</td>\n",
       "      <td>470</td>\n",
       "      <td>2850</td>\n",
       "      <td>62</td>\n",
       "      <td>0.207420</td>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.316195</td>\n",
       "      <td>0.169187</td>\n",
       "      <td>KS_max</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.690493</td>\n",
       "      <td>103</td>\n",
       "      <td>248</td>\n",
       "      <td>3072</td>\n",
       "      <td>82</td>\n",
       "      <td>0.293447</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>0.384328</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>Top10%_score</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.696021</td>\n",
       "      <td>103</td>\n",
       "      <td>240</td>\n",
       "      <td>3080</td>\n",
       "      <td>82</td>\n",
       "      <td>0.300292</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>0.390152</td>\n",
       "      <td>0.097860</td>\n",
       "      <td>Prec&gt;=30%</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790786</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>3181</td>\n",
       "      <td>91</td>\n",
       "      <td>0.403433</td>\n",
       "      <td>0.508108</td>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.066476</td>\n",
       "      <td>F1_max</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluación de umbrales y recomendación",
   "id": "681119528bb94ea4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T21:47:38.408179Z",
     "start_time": "2025-11-10T21:47:38.394181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "thr_path = REPORTS_DIR / \"thresholds_woe_logreg.csv\"\n",
    "thr_df = pd.read_csv(thr_path)\n",
    "\n",
    "# ordenar por umbral\n",
    "thr_df = thr_df.sort_values(\"threshold\").reset_index(drop=True)\n",
    "\n",
    "print(\"=== Evaluación de umbrales ===\")\n",
    "display(thr_df)\n",
    "\n",
    "# Selección según estrategia\n",
    "sel = {}\n",
    "\n",
    "# 1️⃣ Recall alto: prioriza capturar la mayor cantidad de defaults\n",
    "sel[\"Estrategia_recall_alto\"] = thr_df.loc[thr_df[\"name\"].str.contains(\"KS_max\", case=False, na=False)].iloc[0]\n",
    "\n",
    "# 2️⃣ Balanceado: máximo F1\n",
    "sel[\"Estrategia_balanceada\"] = thr_df.loc[thr_df[\"name\"].str.contains(\"F1_max\", case=False, na=False)].iloc[0]\n",
    "\n",
    "# 3️⃣ Precisión alta: objetivo >=30% (si existe)\n",
    "prec_mask = thr_df[\"name\"].str.contains(\"Prec\", case=False, na=False)\n",
    "if prec_mask.any():\n",
    "    sel[\"Estrategia_precision_alta\"] = thr_df.loc[prec_mask].iloc[0]\n",
    "else:\n",
    "    sel[\"Estrategia_precision_alta\"] = thr_df.iloc[thr_df[\"precision\"].idxmax()]\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"\\n=== Recomendaciones de política ===\")\n",
    "for k, row in sel.items():\n",
    "    print(f\"\\n{k}\")\n",
    "    print(f\"  → Umbral sugerido: {row['threshold']:.4f}\")\n",
    "    print(f\"  → Precisión: {row['precision']:.3f}\")\n",
    "    print(f\"  → Recall: {row['recall']:.3f}\")\n",
    "    print(f\"  → F1: {row['f1']:.3f}\")\n",
    "    print(f\"  → Aprobación: {row['approve_rate']*100:.1f}%\")\n",
    "\n",
    "# Guardar resumen\n",
    "out_summary = REPORTS_DIR / \"thresholds_summary_woe_logreg.csv\"\n",
    "pd.DataFrame(sel).T.to_csv(out_summary, index=True)\n",
    "print(f\"\\nResumen guardado en: {out_summary.name}\")\n"
   ],
   "id": "bef5d87a4d43e1f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluación de umbrales ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   threshold   TP    FP    TN  FN  precision    recall        f1  \\\n",
       "0   0.005009  185  3320     0   0   0.052782  1.000000  0.100271   \n",
       "1   0.551453  123   470  2850  62   0.207420  0.664865  0.316195   \n",
       "2   0.690493  103   248  3072  82   0.293447  0.556757  0.384328   \n",
       "3   0.696021  103   240  3080  82   0.300292  0.556757  0.390152   \n",
       "4   0.790786   94   139  3181  91   0.403433  0.508108  0.449761   \n",
       "\n",
       "   approve_rate          name  note  \n",
       "0      1.000000   Recall>=60%   NaN  \n",
       "1      0.169187        KS_max   NaN  \n",
       "2      0.100143  Top10%_score   NaN  \n",
       "3      0.097860     Prec>=30%   NaN  \n",
       "4      0.066476        F1_max   NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>approve_rate</th>\n",
       "      <th>name</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005009</td>\n",
       "      <td>185</td>\n",
       "      <td>3320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Recall&gt;=60%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551453</td>\n",
       "      <td>123</td>\n",
       "      <td>470</td>\n",
       "      <td>2850</td>\n",
       "      <td>62</td>\n",
       "      <td>0.207420</td>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.316195</td>\n",
       "      <td>0.169187</td>\n",
       "      <td>KS_max</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690493</td>\n",
       "      <td>103</td>\n",
       "      <td>248</td>\n",
       "      <td>3072</td>\n",
       "      <td>82</td>\n",
       "      <td>0.293447</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>0.384328</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>Top10%_score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.696021</td>\n",
       "      <td>103</td>\n",
       "      <td>240</td>\n",
       "      <td>3080</td>\n",
       "      <td>82</td>\n",
       "      <td>0.300292</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>0.390152</td>\n",
       "      <td>0.097860</td>\n",
       "      <td>Prec&gt;=30%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.790786</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>3181</td>\n",
       "      <td>91</td>\n",
       "      <td>0.403433</td>\n",
       "      <td>0.508108</td>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.066476</td>\n",
       "      <td>F1_max</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Recomendaciones de política ===\n",
      "\n",
      "Estrategia_recall_alto\n",
      "  → Umbral sugerido: 0.5515\n",
      "  → Precisión: 0.207\n",
      "  → Recall: 0.665\n",
      "  → F1: 0.316\n",
      "  → Aprobación: 16.9%\n",
      "\n",
      "Estrategia_balanceada\n",
      "  → Umbral sugerido: 0.7908\n",
      "  → Precisión: 0.403\n",
      "  → Recall: 0.508\n",
      "  → F1: 0.450\n",
      "  → Aprobación: 6.6%\n",
      "\n",
      "Estrategia_precision_alta\n",
      "  → Umbral sugerido: 0.6960\n",
      "  → Precisión: 0.300\n",
      "  → Recall: 0.557\n",
      "  → F1: 0.390\n",
      "  → Aprobación: 9.8%\n",
      "\n",
      "Resumen guardado en: thresholds_summary_woe_logreg.csv\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venve_product_dev)",
   "language": "python",
   "name": "venve_product_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
